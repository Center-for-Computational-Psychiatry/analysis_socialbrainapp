{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, json, pickle\n",
    "from glob import glob\n",
    "\n",
    "from socialbrainapp import get_demographics, get_oci, get_sds, get_lsas, get_hardball, get_hardball_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load json data\n",
    "json_dir = '../json'\n",
    "out_dir = '../data'\n",
    "json_files = glob(f'{json_dir}/*json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse json data\n",
    "id_lists = {'Demographics':[], 'Hardball':[], 'HardballSubjectiveRatings':[], \n",
    "            'OCI':[], 'SDS':[], 'LSAS':[], 'Journey':[]}\n",
    "\n",
    "df_lists = {'Demographics':[], 'Hardball':[], 'HardballSubjectiveRatings':[], \n",
    "            'OCI':[], 'SDS':[], 'LSAS':[], 'Journey':[]}\n",
    "\n",
    "for json_file in json_files:\n",
    "    try:\n",
    "        with open(json_file, 'rb') as handle:\n",
    "            tmp_data = json.load(handle)\n",
    "        \n",
    "        for element in tmp_data:\n",
    "            \n",
    "            # Get Demographics\n",
    "            if 'Age' in element.keys():\n",
    "                id_lists['Demographics'] += [element['UserId']]\n",
    "                df_lists['Demographics'] += [get_demographics(element)]\n",
    "            \n",
    "            # Get Survey Data\n",
    "            if 'SurveyName' in element.keys():\n",
    "\n",
    "                # Get OCI\n",
    "                if element['SurveyName'] == 'OCI':\n",
    "                    id_lists['OCI'] += [element['UserId']]\n",
    "                    df_lists['OCI'] += [get_oci(element)]\n",
    "\n",
    "                # Get SDS\n",
    "                elif element['SurveyName'] == 'SDS':\n",
    "                    id_lists['SDS'] += [element['UserId']]\n",
    "                    df_lists['SDS'] += [get_sds(element)]\n",
    "\n",
    "                # Get LSAS\n",
    "                elif element['SurveyName'] == 'LSAS':\n",
    "                    id_lists['LSAS'] += [element['UserId']]\n",
    "                    df_lists['LSAS'] += [get_lsas(element)]\n",
    "            \n",
    "            # Get Game Data\n",
    "            if 'Game' in element.keys():\n",
    "                \n",
    "                # Get Hardball\n",
    "                if element['Game'] == 'Hardball':\n",
    "                    if 'Screen' not in element.keys():\n",
    "                        id_lists['Hardball'] += [element['UserId']]\n",
    "                        df_lists['Hardball'] += [get_hardball(element)]\n",
    "\n",
    "                    if 'Screen' in element.keys():\n",
    "                        id_lists['HardballSubjectiveRatings'] += [element['UserId']]\n",
    "                        df_lists['HardballSubjectiveRatings'] += [get_hardball_ratings(element)]\n",
    "                \n",
    "                # Get Journey\n",
    "                if element['Game'] == 'Journey':\n",
    "                    id_lists['Journey'] += [element['UserId']]\n",
    "                    # TBD\n",
    "                    df_lists['Journey'] += [element['UserId']]\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# concatenate all df lists\n",
    "full_dfs = {}\n",
    "for (key, value) in df_lists.items():\n",
    "    if key == 'Journey':\n",
    "        continue\n",
    "    full_dfs[key] = pd.concat(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Data\n",
    "preproc_dfs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01C09A15-F285-4CD1-A1B8-623F60882DE2 120 trials\n",
      "108E056E-5450-4FCF-9B49-7934ECB62AD6 240 trials\n",
      "16ED2B73-2D91-4188-95B3-FE78A3D25B5E 61 trials\n",
      "173C8FF4-084A-4D16-B098-790C15D90CA6 80 trials\n",
      "242DC553-A15C-4150-8067-5081F6FC073A 180 trials\n",
      "26a372c5a72ded55db6e41a2d0df363c 180 trials\n",
      "34D820E8-6CA7-4637-9EE3-EC86C9A7D48D 120 trials\n",
      "40421E3F-4390-4B6B-B062-AF44024E602D 120 trials\n",
      "4A83291D-C22E-4396-985F-536A0BA35F5B 120 trials\n",
      "5523e30b2fa790bb36387f35dd6a8cdb 243 trials\n",
      "5e949e269cc08de572108129acd44eb4 72 trials\n",
      "6FA939D1-7CCB-4D67-8198-7FC95AB013F7 61 trials\n",
      "7ED551B3-9DA3-4FBA-8D2E-F2B50B7ED0BB 120 trials\n",
      "96E84605-8291-42FE-88E3-EA1A8B1F44D6 120 trials\n",
      "99D926F9-32FF-40E8-A5A2-82D29C5BA66C 61 trials\n",
      "AFDE02A6-E690-40AE-A67D-3B38DE3570D9 137 trials\n",
      "BB0C4835-20B4-4219-8041-477C90870CC1 120 trials\n",
      "BB5DA2DF-7B3C-454E-8493-14BC0A93A149 102 trials\n",
      "C5F8E458-27CF-4F09-A320-CCA0ECCCF54A 180 trials\n",
      "D54BE9D4-118D-4E31-9451-60BA924EAF42 71 trials\n",
      "F9D147C1-557E-4B46-89DB-9593CD794F13 93 trials\n",
      "a3e72760af4e109dee51e05a2c95fc2d 64 trials\n",
      "\n",
      "Combining DFs\n",
      "No influence rating for 173C8FF4-084A-4D16-B098-790C15D90CA6\n",
      "No influence rating for 5523e30b2fa790bb36387f35dd6a8cdb\n",
      "No influence rating for 7C8BA30A-5719-489B-AFE8-4D0F286BA02A\n",
      "No influence rating for 5e949e269cc08de572108129acd44eb4\n",
      "No influence rating for C5F8E458-27CF-4F09-A320-CCA0ECCCF54A\n",
      "No influence rating for a3e72760af4e109dee51e05a2c95fc2d\n",
      "No influence rating for 96E84605-8291-42FE-88E3-EA1A8B1F44D6\n",
      "No influence rating for 40421E3F-4390-4B6B-B062-AF44024E602D\n",
      "No influence rating for 01C09A15-F285-4CD1-A1B8-623F60882DE2\n",
      "No influence rating for 108E056E-5450-4FCF-9B49-7934ECB62AD6\n",
      "No influence rating for F9D147C1-557E-4B46-89DB-9593CD794F13\n",
      "No influence rating for 26a372c5a72ded55db6e41a2d0df363c\n",
      "No influence rating for AFDE02A6-E690-40AE-A67D-3B38DE3570D9\n",
      "No influence rating for BB0C4835-20B4-4219-8041-477C90870CC1\n"
     ]
    }
   ],
   "source": [
    "# remove Hardball subjects with less than 60 completed trials\n",
    "preproc_dfs['Hardball'] = full_dfs['Hardball'].copy()\n",
    "preproc_dfs['HardballSubjectiveRatings'] = full_dfs['HardballSubjectiveRatings'].copy()\n",
    "\n",
    "for subj_id in np.unique(full_dfs['Hardball'].index):\n",
    "    ntrials = len(full_dfs['Hardball'][full_dfs['Hardball'].index==subj_id])\n",
    "    if ntrials < 60:\n",
    "        preproc_dfs['Hardball'] = preproc_dfs['Hardball'].drop(subj_id)\n",
    "        try:\n",
    "            preproc_dfs['HardballSubjectiveRatings'] = preproc_dfs['HardballSubjectiveRatings'].drop(subj_id)\n",
    "        except:\n",
    "            continue\n",
    "    elif ntrials > 60:\n",
    "        print(subj_id, f'{ntrials} trials')\n",
    "\n",
    "preproc_dfs['HardballSubjectiveRatings'].to_csv(f'{out_dir}/HardballSubjectiveRatings-data.csv', index_label='SubjectID')\n",
    "\n",
    "# combine dfs\n",
    "print('\\nCombining DFs')\n",
    "text_to_display = []\n",
    "preproc_dfs['Hardball'] = preproc_dfs['Hardball'].reset_index()\n",
    "\n",
    "for idx in preproc_dfs['Hardball'].index:\n",
    "    subj_id = preproc_dfs['Hardball']['index'][idx]\n",
    "    team_id = preproc_dfs['Hardball']['TeamName'][idx]\n",
    "    year_id = preproc_dfs['Hardball']['Year'][idx]\n",
    "    month_id = preproc_dfs['Hardball']['Month'][idx]\n",
    "    day_id = preproc_dfs['Hardball']['Day'][idx]\n",
    "\n",
    "    try:\n",
    "        influence_rating = float(preproc_dfs['HardballSubjectiveRatings'][(preproc_dfs['HardballSubjectiveRatings']['TeamName']==team_id) & (preproc_dfs['HardballSubjectiveRatings']['Year']==year_id) & (preproc_dfs['HardballSubjectiveRatings']['Month']==month_id) & (preproc_dfs['HardballSubjectiveRatings']['Day']==day_id)].at[subj_id, 'Rate'])\n",
    "        preproc_dfs['Hardball'].at[idx, 'InfluenceRating'] = influence_rating\n",
    "    except:\n",
    "        if f'No influence rating for {subj_id}' not in text_to_display:\n",
    "            text_to_display += [f'No influence rating for {subj_id}']\n",
    "            print(f'No influence rating for {subj_id}')\n",
    "        continue\n",
    "\n",
    "preproc_dfs['Hardball'] = preproc_dfs['Hardball'].set_index('index')\n",
    "preproc_dfs['Hardball'].to_csv(f'{out_dir}/Hardball-data.csv', index_label='SubjectID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove OCI subjects with less than 19 completed trials\n",
    "preproc_dfs['OCI'] = full_dfs['OCI'].copy()\n",
    "for subj_id in np.unique(full_dfs['OCI'].index):\n",
    "    if len(full_dfs['OCI'][full_dfs['OCI'].index==subj_id]) != 19:\n",
    "        preproc_dfs['OCI'] = preproc_dfs['OCI'].drop(subj_id)\n",
    "\n",
    "preproc_dfs['OCI'].to_csv(f'{out_dir}/OCI-data.csv', index_label='SubjectID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove SDS subjects with less than 21 completed trials\n",
    "preproc_dfs['SDS'] = full_dfs['SDS'].copy()\n",
    "for subj_id in np.unique(full_dfs['SDS'].index):\n",
    "    if len(full_dfs['SDS'][full_dfs['SDS'].index==subj_id]) != 21:\n",
    "        preproc_dfs['SDS'] = preproc_dfs['SDS'].drop(subj_id)\n",
    "\n",
    "preproc_dfs['SDS'].to_csv(f'{out_dir}/SDS-data.csv', index_label='SubjectID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove LSAS subjects with less than 24 completed trials\n",
    "preproc_dfs['LSAS'] = full_dfs['LSAS'].copy()\n",
    "for subj_id in np.unique(full_dfs['LSAS'].index):\n",
    "    if len(full_dfs['LSAS'][full_dfs['LSAS'].index==subj_id]) != 24:\n",
    "        preproc_dfs['LSAS'] = preproc_dfs['LSAS'].drop(subj_id)\n",
    "\n",
    "preproc_dfs['LSAS'].to_csv(f'{out_dir}/LSAS-data.csv', index_label='SubjectID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save demographics\n",
    "preproc_dfs['Demographics'] = full_dfs['Demographics'].copy()\n",
    "preproc_dfs['Demographics'].to_csv(f'{out_dir}/Demographics-data.csv', index_label='SubjectID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as pickle\n",
    "with open(f'{out_dir}/SocialBrainAppData.pickle', 'wb') as handle:\n",
    "    pickle.dump(preproc_dfs, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Unique IDs with Any Data\n",
      "Demographics 258\n",
      "Hardball 117\n",
      "HardballSubjectiveRatings 91\n",
      "OCI 136\n",
      "SDS 121\n",
      "LSAS 66\n",
      "Journey 215\n"
     ]
    }
   ],
   "source": [
    "print('Total Number of Unique IDs with Any Data')\n",
    "for name, id_list in id_lists.items():\n",
    "    print(name, len(np.unique(id_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Unique IDs with Complete Data\n",
      "Hardball 94\n",
      "HardballSubjectiveRatings 91\n",
      "OCI 110\n",
      "SDS 94\n",
      "LSAS 52\n",
      "Demographics 258\n"
     ]
    }
   ],
   "source": [
    "print('Total Number of Unique IDs with Complete Data')\n",
    "for name, id_list in preproc_dfs.items():\n",
    "    print(name, len(np.unique(id_list.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Development: this is a good data file\n",
    "# json_file = '..\\\\data\\\\2022-07-15_07-00__sb_data.json'\n",
    "# with open(json_file, 'rb') as handle:\n",
    "#     tmp_data = json.load(handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61ddb848442542d36173afe0f0b741b25de113b281e5ea85dfc8be971b019a7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
