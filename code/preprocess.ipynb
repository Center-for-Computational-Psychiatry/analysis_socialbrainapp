{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, json, pickle, os, warnings\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "from socialbrainapp import get_demographics, get_oci, get_sds, get_lsas, get_hardball, get_hardball_ratings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get today's date\n",
    "todays_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Load json data\n",
    "json_dir = '../json'\n",
    "out_dir = '../data'\n",
    "json_files = glob(f'{json_dir}/*json')\n",
    "len(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parse json data\n",
    "id_lists = {'Demographics':[], 'Hardball':[], 'HardballSubjectiveRatings':[], \n",
    "            'OCI':[], 'SDS':[], 'LSAS':[], \n",
    "            'Journey_decisions':[], 'Journey_memory':[], 'Journey_dots':[], 'Journey_characters':[]}\n",
    "\n",
    "df_lists = {'Demographics':[], 'Hardball':[], 'HardballSubjectiveRatings':[], \n",
    "            'OCI':[], 'SDS':[], 'LSAS':[],\n",
    "            'Journey_decisions':[], 'Journey_memory':[], 'Journey_dots':[], 'Journey_characters':[]}\n",
    "\n",
    "for json_file in json_files:\n",
    "    try:\n",
    "        with open(json_file, 'rb') as handle:\n",
    "            tmp_data = json.load(handle)\n",
    "\n",
    "        for element in tmp_data:\n",
    "\n",
    "            # Get Demographics\n",
    "            if 'Age' in element.keys():\n",
    "                id_lists['Demographics'] += [element['UserId']]\n",
    "                df_lists['Demographics'] += [get_demographics(element)]\n",
    "\n",
    "            # Get Survey Data\n",
    "            if 'SurveyName' in element.keys():\n",
    "\n",
    "                # Get OCI\n",
    "                if element['SurveyName'] == 'OCI':\n",
    "                    id_lists['OCI'] += [element['UserId']]\n",
    "                    df_lists['OCI'] += [get_oci(element)]\n",
    "\n",
    "                # Get SDS\n",
    "                elif element['SurveyName'] == 'SDS':\n",
    "                    id_lists['SDS'] += [element['UserId']]\n",
    "                    df_lists['SDS'] += [get_sds(element)]\n",
    "\n",
    "                # Get LSAS\n",
    "                elif element['SurveyName'] == 'LSAS':\n",
    "                    id_lists['LSAS'] += [element['UserId']]\n",
    "                    df_lists['LSAS'] += [get_lsas(element)]\n",
    "\n",
    "            # Get Game Data\n",
    "            if 'Game' in element.keys():\n",
    "                # Get Hardball\n",
    "                if element['Game'] == 'Hardball':\n",
    "                    if 'Screen' not in element.keys():\n",
    "                        id_lists['Hardball'] += [element['UserId']]\n",
    "                        df_lists['Hardball'] += [get_hardball(element)]\n",
    "\n",
    "                    if 'Screen' in element.keys():\n",
    "                        id_lists['HardballSubjectiveRatings'] += [element['UserId']]\n",
    "                        df_lists['HardballSubjectiveRatings'] += [get_hardball_ratings(element)]\n",
    "\n",
    "                # Get Journey\n",
    "                if element['Game'] == 'Journey':\n",
    "                    try:\n",
    "                        task_name, snt_df = get_journey(element)\n",
    "                        if len(task_name) > 0: \n",
    "                            id_lists['Journey_'+task_name] += [element['UserId']]\n",
    "                            df_lists['Journey_'+task_name] += [snt_df]\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# concatenate all df lists\n",
    "full_dfs = {}\n",
    "for (key, value) in df_lists.items():\n",
    "    if len(value) > 0: \n",
    "        full_dfs[key] = []\n",
    "        full_dfs[key] = pd.concat(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Data\n",
    "preproc_dfs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01C09A15-F285-4CD1-A1B8-623F60882DE2 120 trials\n",
      "108E056E-5450-4FCF-9B49-7934ECB62AD6 240 trials\n",
      "16ED2B73-2D91-4188-95B3-FE78A3D25B5E 61 trials\n",
      "173C8FF4-084A-4D16-B098-790C15D90CA6 80 trials\n",
      "242DC553-A15C-4150-8067-5081F6FC073A 180 trials\n",
      "26a372c5a72ded55db6e41a2d0df363c 180 trials\n",
      "34D820E8-6CA7-4637-9EE3-EC86C9A7D48D 120 trials\n",
      "40421E3F-4390-4B6B-B062-AF44024E602D 120 trials\n",
      "4A83291D-C22E-4396-985F-536A0BA35F5B 120 trials\n",
      "5523e30b2fa790bb36387f35dd6a8cdb 243 trials\n",
      "5e949e269cc08de572108129acd44eb4 72 trials\n",
      "6FA939D1-7CCB-4D67-8198-7FC95AB013F7 61 trials\n",
      "78F52907-6E6B-4FBE-BF52-78300B51B77B 120 trials\n",
      "7ED551B3-9DA3-4FBA-8D2E-F2B50B7ED0BB 180 trials\n",
      "96E84605-8291-42FE-88E3-EA1A8B1F44D6 120 trials\n",
      "99D926F9-32FF-40E8-A5A2-82D29C5BA66C 61 trials\n",
      "AFDE02A6-E690-40AE-A67D-3B38DE3570D9 137 trials\n",
      "BB0C4835-20B4-4219-8041-477C90870CC1 120 trials\n",
      "BB5DA2DF-7B3C-454E-8493-14BC0A93A149 102 trials\n",
      "C5F8E458-27CF-4F09-A320-CCA0ECCCF54A 180 trials\n",
      "D54BE9D4-118D-4E31-9451-60BA924EAF42 71 trials\n",
      "F9D147C1-557E-4B46-89DB-9593CD794F13 93 trials\n",
      "a3e72760af4e109dee51e05a2c95fc2d 64 trials\n",
      "\n",
      "Combining DFs\n",
      "No influence rating for 173C8FF4-084A-4D16-B098-790C15D90CA6\n",
      "No influence rating for 5523e30b2fa790bb36387f35dd6a8cdb\n",
      "No influence rating for 7C8BA30A-5719-489B-AFE8-4D0F286BA02A\n",
      "No influence rating for 5e949e269cc08de572108129acd44eb4\n",
      "No influence rating for C5F8E458-27CF-4F09-A320-CCA0ECCCF54A\n",
      "No influence rating for a3e72760af4e109dee51e05a2c95fc2d\n",
      "No influence rating for 96E84605-8291-42FE-88E3-EA1A8B1F44D6\n",
      "No influence rating for 40421E3F-4390-4B6B-B062-AF44024E602D\n",
      "No influence rating for 01C09A15-F285-4CD1-A1B8-623F60882DE2\n",
      "No influence rating for 108E056E-5450-4FCF-9B49-7934ECB62AD6\n",
      "No influence rating for F9D147C1-557E-4B46-89DB-9593CD794F13\n",
      "No influence rating for 26a372c5a72ded55db6e41a2d0df363c\n",
      "No influence rating for AFDE02A6-E690-40AE-A67D-3B38DE3570D9\n",
      "No influence rating for BB0C4835-20B4-4219-8041-477C90870CC1\n",
      "No influence rating for 78F52907-6E6B-4FBE-BF52-78300B51B77B\n"
     ]
    }
   ],
   "source": [
    "# remove Hardball subjects with less than 60 completed trials\n",
    "preproc_dfs['Hardball'] = full_dfs['Hardball'].copy()\n",
    "preproc_dfs['HardballSubjectiveRatings'] = full_dfs['HardballSubjectiveRatings'].copy()\n",
    "\n",
    "for subj_id in np.unique(full_dfs['Hardball'].index):\n",
    "    ntrials = len(full_dfs['Hardball'][full_dfs['Hardball'].index==subj_id])\n",
    "    if ntrials < 60:\n",
    "        preproc_dfs['Hardball'] = preproc_dfs['Hardball'].drop(subj_id)\n",
    "        try:\n",
    "            preproc_dfs['HardballSubjectiveRatings'] = preproc_dfs['HardballSubjectiveRatings'].drop(subj_id)\n",
    "        except:\n",
    "            continue\n",
    "    elif ntrials > 60:\n",
    "        print(subj_id, f'{ntrials} trials')\n",
    "        preproc_dfs['Hardball'].at[subj_id, 'NTrials'] = ntrials\n",
    "        preproc_dfs['Hardball'].at[subj_id, 'Include'] = np.nan\n",
    "    else:\n",
    "        preproc_dfs['Hardball'].at[subj_id, 'NTrials'] = ntrials\n",
    "        preproc_dfs['Hardball'].at[subj_id, 'Include'] = 1\n",
    "\n",
    "preproc_dfs['HardballSubjectiveRatings'].to_csv(f'{out_dir}/HardballSubjectiveRatings-data-{todays_date}.csv', index_label='SubjectID')\n",
    "\n",
    "# combine dfs\n",
    "print('\\nCombining DFs')\n",
    "text_to_display = []\n",
    "preproc_dfs['Hardball'] = preproc_dfs['Hardball'].reset_index()\n",
    "\n",
    "for idx in preproc_dfs['Hardball'].index:\n",
    "    subj_id = preproc_dfs['Hardball']['index'][idx]\n",
    "    team_id = preproc_dfs['Hardball']['TeamName'][idx]\n",
    "    year_id = preproc_dfs['Hardball']['Year'][idx]\n",
    "    month_id = preproc_dfs['Hardball']['Month'][idx]\n",
    "    day_id = preproc_dfs['Hardball']['Day'][idx]\n",
    "\n",
    "    try:\n",
    "        influence_rating = float(preproc_dfs['HardballSubjectiveRatings'][(preproc_dfs['HardballSubjectiveRatings']['TeamName']==team_id) & (preproc_dfs['HardballSubjectiveRatings']['Year']==year_id) & (preproc_dfs['HardballSubjectiveRatings']['Month']==month_id) & (preproc_dfs['HardballSubjectiveRatings']['Day']==day_id)].at[subj_id, 'Rate'])\n",
    "        preproc_dfs['Hardball'].at[idx, 'InfluenceRating'] = influence_rating\n",
    "    except:\n",
    "        if f'No influence rating for {subj_id}' not in text_to_display:\n",
    "            text_to_display += [f'No influence rating for {subj_id}']\n",
    "            print(f'No influence rating for {subj_id}')\n",
    "        continue\n",
    "\n",
    "preproc_dfs['Hardball'] = preproc_dfs['Hardball'].set_index('index')\n",
    "# preproc_dfs['Hardball'].to_csv(f'{out_dir}/Hardball-data-{todays_date}.csv', index_label='SubjectID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "070048E2-CE06-491C-880D-6C954943E843 20\n",
      "1A207FB8-923E-4EB2-81AA-D1AC181E670D 20\n",
      "202788DB-1A75-448A-81EB-6482C5B97C1E 20\n",
      "34D820E8-6CA7-4637-9EE3-EC86C9A7D48D 20\n",
      "40421E3F-4390-4B6B-B062-AF44024E602D 20\n",
      "5523e30b2fa790bb36387f35dd6a8cdb 32\n",
      "5FD03A4A-77A6-41BD-A4C8-D2EB9130E911 20\n",
      "669DD1DC-EB3A-4A7B-A75E-3037C9A38778 38\n",
      "6884BFED-4F1C-4C91-9AE5-DCCCFC029491 76\n",
      "695A9C75-000E-4781-8552-33E2C528F582 25\n",
      "7ED551B3-9DA3-4FBA-8D2E-F2B50B7ED0BB 38\n",
      "8A2D0E6B-11C7-40EF-9E99-D1C3D8CAFA62 20\n",
      "8BA72A5B-E3EF-4DF6-9F6F-E28085099DD4 21\n",
      "A298839E-25D2-4BB3-A43E-346FE2D73920 20\n",
      "A428C902-3440-4AA8-9617-56BA7D16277D 41\n",
      "A73B20D3-B9CE-4099-9BB7-6C138D862A82 39\n",
      "B5C7CB4C-3059-4A5C-9896-93E16CE1B56D 38\n",
      "B642A2A5-9082-4BDA-A2B4-A9C3EA98A2FF 21\n",
      "BB5DA2DF-7B3C-454E-8493-14BC0A93A149 22\n",
      "E6EDEED0-0542-439B-8E28-B63D2D44D1F8 38\n",
      "F0D85366-F2B3-4AFC-A0DA-3FD41AC72B45 20\n"
     ]
    }
   ],
   "source": [
    "full_dfs['OCI'].to_csv(f'{out_dir}/OCI-rawdata-{todays_date}.csv', index_label='SubjectID')\n",
    "\n",
    "# remove OCI subjects with less than 19 completed trials\n",
    "tmp_dflist = []\n",
    "for subj_id in np.unique(full_dfs['OCI'].index):\n",
    "    subj_df = full_dfs['OCI'].loc[subj_id]\n",
    "    if len(subj_df) == 19: # completed survey once\n",
    "        # grab attention check\n",
    "        attn_check = float(subj_df[subj_df['SurveyQuestion']==15]['Response'])\n",
    "\n",
    "        # long to wide, exclude attention check\n",
    "        subj_df = subj_df[subj_df['SurveyQuestion']!=15].pivot(columns='SurveyQuestion', values='Response').add_prefix('OCI_')\n",
    "\n",
    "        subj_df['OCI_Total'] = subj_df.sum(axis=1, skipna=False)\n",
    "\n",
    "        if np.isnan(attn_check):\n",
    "            subj_df['OCI_AttnCheck'] = 1\n",
    "        else:\n",
    "            subj_df['OCI_AttnCheck'] = 0\n",
    "\n",
    "        tmp_dflist += [subj_df]\n",
    "    elif len(subj_df) > 19:\n",
    "        print(subj_id, len(subj_df))\n",
    "\n",
    "preproc_dfs['OCI'] = pd.concat(tmp_dflist)\n",
    "preproc_dfs['OCI'].to_csv(f'{out_dir}/OCI-data-{todays_date}.csv', index_label='SubjectID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0ECD14EC-631D-4923-8DD4-D4A3E2FAFDBC 42\n",
      "15A081D3-32F5-4740-9A93-D133D707C099 22\n",
      "15C38FDF-2C9C-431A-BDF3-D886E47AAFAD 22\n",
      "2558849D-F345-40B9-BC1B-22987A2EB9C8 22\n",
      "321BCD37-998E-4F7C-A8FF-6C4E799FB6D4 22\n",
      "43111F06-A728-47B9-B13E-288F48AA3238 42\n",
      "451edd83489e8b126787c91fc1ca0fa6 22\n",
      "5523e30b2fa790bb36387f35dd6a8cdb 23\n",
      "5FD03A4A-77A6-41BD-A4C8-D2EB9130E911 42\n",
      "669DD1DC-EB3A-4A7B-A75E-3037C9A38778 42\n",
      "6884BFED-4F1C-4C91-9AE5-DCCCFC029491 42\n",
      "8312DACF-5F5F-4BEC-9AC8-2F3CE0D0C47E 42\n",
      "8611425A-D1FE-4F99-A92E-A67D05E08460 22\n",
      "86DD495C-3C25-41F1-9872-47A60A992DAC 22\n",
      "8BA72A5B-E3EF-4DF6-9F6F-E28085099DD4 22\n",
      "8F4C21EF-5003-4DCA-BE31-1B2055D9C002 42\n",
      "96E84605-8291-42FE-88E3-EA1A8B1F44D6 24\n",
      "A12F15C6-4123-49F6-A2F9-C32A9A3F1205 22\n",
      "B6C35BD6-EE25-4243-96BF-A9D85BC97D22 25\n",
      "E3E9B23D-D3EB-4F3F-99E9-8D6E8FEB3246 22\n",
      "F9E76FC7-94F3-4C41-A3A0-F80274451097 42\n"
     ]
    }
   ],
   "source": [
    "full_dfs['SDS'].to_csv(f'{out_dir}/SDS-rawdata-{todays_date}.csv', index_label='SubjectID')\n",
    "\n",
    "# remove SDS subjects with less than 21 completed trials\n",
    "tmp_dflist = []\n",
    "for subj_id in np.unique(full_dfs['SDS'].index):\n",
    "    subj_df = full_dfs['SDS'].loc[subj_id]\n",
    "    if len(subj_df) == 21: # completed survey once\n",
    "        # grab attention check\n",
    "        attn_check = float(subj_df[subj_df['SurveyQuestion']==16]['Response'])\n",
    "\n",
    "        # long to wide, exclude attention check\n",
    "        subj_df = subj_df[subj_df['SurveyQuestion']!=16].pivot(columns='SurveyQuestion', values='Response').add_prefix('SDS_')\n",
    "\n",
    "        subj_df['SDS_Total'] = subj_df.sum(axis=1, skipna=False)\n",
    "\n",
    "        if np.isnan(attn_check):\n",
    "            subj_df['SDS_AttnCheck'] = 1\n",
    "        else:\n",
    "            subj_df['SDS_AttnCheck'] = 0\n",
    "\n",
    "        tmp_dflist += [subj_df]\n",
    "    elif len(subj_df) > 21:\n",
    "        print(subj_id, len(subj_df))\n",
    "\n",
    "preproc_dfs['SDS'] = pd.concat(tmp_dflist)\n",
    "preproc_dfs['SDS'].to_csv(f'{out_dir}/SDS-data-{todays_date}.csv', index_label='SubjectID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08C278D1-4F43-4B78-9442-69CA52224A97 48\n",
      "26a372c5a72ded55db6e41a2d0df363c 48\n",
      "4B574E29-4B9D-4B6B-9AEB-40A981407001 25\n",
      "62C52355-6880-45EF-B09D-7DD3546E5A24 25\n",
      "6884BFED-4F1C-4C91-9AE5-DCCCFC029491 48\n",
      "A298839E-25D2-4BB3-A43E-346FE2D73920 25\n",
      "CFC6E9E1-5CF8-4971-9B7A-512179DEB71B 25\n",
      "DC7D480F-01FB-4352-ABB8-D16E673A378F 47\n",
      "E3E9B23D-D3EB-4F3F-99E9-8D6E8FEB3246 27\n",
      "F0D85366-F2B3-4AFC-A0DA-3FD41AC72B45 25\n",
      "F67AA14F-4FCB-4FFF-903A-A469DB86EC74 25\n",
      "d485fe9a2ade8e0a8ea7cc43a0773032 25\n",
      "ee7be7b03598aebbff76aa12004bdca9 25\n"
     ]
    }
   ],
   "source": [
    "full_dfs['LSAS'].to_csv(f'{out_dir}/LSAS-rawdata-{todays_date}.csv', index_label='SubjectID')\n",
    "\n",
    "# remove LSAS subjects with less than 24 completed trials\n",
    "tmp_dflist = []\n",
    "for subj_id in np.unique(full_dfs['LSAS'].index):\n",
    "    subj_df = full_dfs['LSAS'].loc[subj_id]\n",
    "    if len(subj_df) == 24: # completed survey once\n",
    "        # long to wide, exclude attention check\n",
    "        subj_df = subj_df.pivot(columns='SurveyQuestion', values='Response').add_prefix('LSAS_')\n",
    "\n",
    "        subj_df['LSAS_Total'] = subj_df.sum(axis=1, skipna=False)\n",
    "\n",
    "        tmp_dflist += [subj_df]\n",
    "    elif len(subj_df) > 24:\n",
    "        print(subj_id, len(subj_df))\n",
    "\n",
    "preproc_dfs['LSAS'] = pd.concat(tmp_dflist)\n",
    "preproc_dfs['LSAS'].to_csv(f'{out_dir}/LSAS-data-{todays_date}.csv', index_label='SubjectID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save demographics\n",
    "preproc_dfs['Demographics'] = full_dfs['Demographics'].copy()\n",
    "preproc_dfs['Demographics'] = preproc_dfs['Demographics'].join(preproc_dfs['LSAS'])\n",
    "preproc_dfs['Demographics'] = preproc_dfs['Demographics'].join(preproc_dfs['OCI'])\n",
    "preproc_dfs['Demographics'] = preproc_dfs['Demographics'].join(preproc_dfs['SDS'])\n",
    "preproc_dfs['Demographics'].to_csv(f'{out_dir}/Demographics-data-{todays_date}.csv', index_label='SubjectID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as pickle\n",
    "with open(f'{out_dir}/SocialBrainAppData-{todays_date}.pickle', 'wb') as handle:\n",
    "    pickle.dump(preproc_dfs, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Unique IDs with Any Data\n",
      "Demographics 270\n",
      "Hardball 123\n",
      "HardballSubjectiveRatings 95\n",
      "OCI 143\n",
      "SDS 127\n",
      "LSAS 70\n",
      "Journey 225\n"
     ]
    }
   ],
   "source": [
    "print('Total Number of Unique IDs with Any Data')\n",
    "for name, id_list in id_lists.items():\n",
    "    print(name, len(np.unique(id_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Unique IDs with Complete Data\n",
      "Hardball 98\n",
      "HardballSubjectiveRatings 95\n",
      "OCI 113\n",
      "SDS 99\n",
      "LSAS 55\n",
      "Demographics 270\n"
     ]
    }
   ],
   "source": [
    "print('Total Number of Unique IDs with Complete Data')\n",
    "for name, id_list in preproc_dfs.items():\n",
    "    print(name, len(np.unique(id_list.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move files after preprocessing is completed\n",
    "for json_file in json_files:\n",
    "    os.rename(json_file, f'{json_dir}/processed/{os.path.basename(json_file)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Development: this is a good data file\n",
    "# json_file = '..\\\\data\\\\2022-07-15_07-00__sb_data.json'\n",
    "# with open(json_file, 'rb') as handle:\n",
    "#     tmp_data = json.load(handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "61ddb848442542d36173afe0f0b741b25de113b281e5ea85dfc8be971b019a7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
